{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import scale, normalize, MinMaxScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.io import arff\n",
    "\n",
    "from inputlds import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(g,f_dash,proc_noise_std,obs_noise_std,inputs,T):\n",
    "    \"\"\"\n",
    "    parametrs for dynamical_syste(A,B,C,D, **kwargs)\n",
    "    input: A,B,C,D, **kwargs\n",
    "    phi_(t+1) = A*phi_t + B*X_t + w_(t+1)\n",
    "        Y_t = C*phi_t + D*X_t + v_t\n",
    "    A--> g:[n,n] \n",
    "    B--> B:[n,d] matrix for inputs, d is the dimension of inputs\n",
    "    C--> f_dash:[m,n] \n",
    "    D--> D:[m,d] matrix for inputs, d is the dimension of inputs\n",
    "    n is the dimension of hidden states (phi: [T,n]);\n",
    "    m is the dimension of observations (Y: [T,m]);\n",
    "    d is the dimension of inputs (X: [T,d]).\n",
    "    \n",
    "    \"\"\"\n",
    "    n=len(g)\n",
    "    m=len(f_dash)\n",
    "    if inputs == 0: # no inputs\n",
    "        inputs = np.zeros((m,T))\n",
    "    dim = len(inputs) # dimension of inputs\n",
    "    ds1 = dynamical_system(g,np.zeros((n,dim)),f_dash,np.zeros((m,dim)),\n",
    "            process_noise='gaussian',\n",
    "            observation_noise='gaussian', \n",
    "            process_noise_std=proc_noise_std, \n",
    "            observation_noise_std=obs_noise_std)\n",
    "\n",
    "    h0=np.ones(ds1.d) # initial state\n",
    "    ds1.solve(h0=h0, inputs=inputs, T=T)\n",
    "    return np.asarray(ds1.outputs).reshape(T,m) #.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=2, M=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.04 0.06 0.08] [0.02 0.04 0.06 0.08]\n"
     ]
    }
   ],
   "source": [
    "# n=2 m=2\n",
    "# Set parameters\n",
    "start=0.02\n",
    "stop=0.1\n",
    "step=0.02\n",
    "T=20\n",
    "\n",
    "# Collect the nrmse value for each experiment\n",
    "pro_rang = np.arange(start,stop,step)\n",
    "obs_rang = np.arange(start,stop,step)\n",
    "print(pro_rang, obs_rang)\n",
    "proL=len(pro_rang)\n",
    "obsL=len(obs_rang)\n",
    "\n",
    "g_1 = 0.8*np.matrix([[0.9,0.2],[0.1,0.1]])\n",
    "f_dash_1 = 0.8*np.matrix([[1.0,1.0],[0.2,0.2]])\n",
    "\n",
    "g_2 = 0.8*np.matrix([[0.8,0.2],[0.2,0.1]])\n",
    "f_dash_2 = 0.8*np.matrix([[0.8,1.0],[0.1,0.2]])\n",
    "\n",
    "cluster_1 = []\n",
    "cluster_2 = []\n",
    "\n",
    "for i in range(proL):\n",
    "    for j in range(obsL):\n",
    "        proc_noise_std=pro_rang[i]\n",
    "        obs_noise_std=obs_rang[j]\n",
    "        # Generate data\n",
    "        # inputs = np.zeros((2,T))\n",
    "        inputs = 0\n",
    "        for k in range(10):\n",
    "            data_1 = data_generation(g_1,f_dash_1,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_1.append(data_1)\n",
    "            \n",
    "            data_2 = data_generation(g_2,f_dash_2,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_2.append(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 20, 2) (320,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate((np.array(cluster_1),np.array(cluster_2)),axis=0)\n",
    "Y_label = np.concatenate((np.zeros(len(cluster_1)),np.ones(len(cluster_2))),axis=0)\n",
    "print(Y.shape, Y_label.shape)\n",
    "data = Y.reshape(320,-1)\n",
    "with open('2_2_test.npy', 'wb') as f:\n",
    "    np.save(f, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=3,M=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.04 0.06 0.08] [0.02 0.04 0.06 0.08]\n"
     ]
    }
   ],
   "source": [
    "# n=6 m=2\n",
    "# Set parameters\n",
    "start=0.02\n",
    "stop=0.1\n",
    "step=0.02\n",
    "T=20\n",
    "\n",
    "# Collect the nrmse value for each experiment\n",
    "pro_rang = np.arange(start,stop,step)\n",
    "obs_rang = np.arange(start,stop,step)\n",
    "print(pro_rang, obs_rang)\n",
    "proL=len(pro_rang)\n",
    "obsL=len(obs_rang)\n",
    "\n",
    "g_1 = 0.6*np.matrix([[1.0,0.8,0.8],[0.6,0.1,0.2],[0.3,0.2,0.2]]) #6,6\n",
    "f_dash_1 = 0.6*np.matrix([[0.7,0.4,0.3],[0.2,0.6,0.2]]) #2,6\n",
    "\n",
    "g_2 = 0.6*np.matrix([[1.0,1.0,0.6],[0.7,0.2,0.2],[0.2,0.1,0.1]])\n",
    "f_dash_2 = 0.6*np.matrix([[0.5,0.4,0.1],[0.2,0.5,0.1]])\n",
    "\n",
    "cluster_1 = []\n",
    "cluster_2 = []\n",
    "\n",
    "for i in range(proL):\n",
    "    for j in range(obsL):\n",
    "        proc_noise_std=pro_rang[i]\n",
    "        obs_noise_std=obs_rang[j]\n",
    "        # Generate data\n",
    "        # inputs = np.zeros((2,T))\n",
    "        inputs = 0\n",
    "        for k in range(10):\n",
    "            data_1 = data_generation(g_1,f_dash_1,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_1.append(data_1)\n",
    "            \n",
    "            data_2 = data_generation(g_2,f_dash_2,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_2.append(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 20, 2) (320,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate((np.array(cluster_1),np.array(cluster_2)),axis=0)\n",
    "Y_label = np.concatenate((np.zeros(len(cluster_1)),np.ones(len(cluster_2))),axis=0)\n",
    "print(Y.shape, Y_label.shape)\n",
    "data = Y.reshape(320,-1)\n",
    "with open('3_2_test.npy', 'wb') as f:\n",
    "    np.save(f, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N=4, M=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02 0.04 0.06 0.08] [0.02 0.04 0.06 0.08]\n"
     ]
    }
   ],
   "source": [
    "# n=4 m=2\n",
    "# Set parameters\n",
    "start=0.02\n",
    "stop=0.1\n",
    "step=0.02\n",
    "T=20\n",
    "\n",
    "# Collect the nrmse value for each experiment\n",
    "pro_rang = np.arange(start,stop,step)\n",
    "obs_rang = np.arange(start,stop,step)\n",
    "print(pro_rang, obs_rang)\n",
    "proL=len(pro_rang)\n",
    "obsL=len(obs_rang)\n",
    "\n",
    "g_1 = np.matrix([[0.9,0.8,0.5,0.2],[0.9,0.1,0.3,0.4],[0.8,0.2,0.1,0.1],[0.1,0.1,0.1,0.7]])*0.4 #4,4\n",
    "f_dash_1 = np.matrix([[0.2,0.5,0.1,0.1],[0.8,0.6,0.1,0.1]])*0.4 #2,4\n",
    "\n",
    "g_2 = np.matrix([[1.0,0.8,0.5,0.3],[0.6,0.2,0.3,0.4],[0.8,0.2,0.3,0.1],[0.2,0.2,0.3,0.7]])*0.4\n",
    "f_dash_2 = np.matrix([[0.2,0.4,0.1,0.1],[0.6,0.2,0.2,0.2]])*0.4\n",
    "\n",
    "cluster_1 = []\n",
    "cluster_2 = []\n",
    "\n",
    "for i in range(proL):\n",
    "    for j in range(obsL):\n",
    "        proc_noise_std=pro_rang[i]\n",
    "        obs_noise_std=obs_rang[j]\n",
    "        # Generate data\n",
    "        # inputs = np.zeros((2,T))\n",
    "        inputs = 0\n",
    "        for k in range(10):\n",
    "            data_1 = data_generation(g_1,f_dash_1,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_1.append(data_1)\n",
    "            \n",
    "            data_2 = data_generation(g_2,f_dash_2,proc_noise_std,obs_noise_std,inputs,T)\n",
    "            cluster_2.append(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 20, 2) (320,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate((np.array(cluster_1),np.array(cluster_2)),axis=0)\n",
    "Y_label = np.concatenate((np.zeros(len(cluster_1)),np.ones(len(cluster_2))),axis=0)\n",
    "print(Y.shape, Y_label.shape)\n",
    "data = Y.reshape(320,-1)\n",
    "with open('4_2_test.npy', 'wb') as f:\n",
    "    np.save(f, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = \"ECG5000/ECG5000_TRAIN.arff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a2p(path):\n",
    "    # 读取ARFF文件\n",
    "    data, meta = arff.loadarff(path)  # 将 'your_file.arff' 替换为你的ARFF文件路径\n",
    "\n",
    "    # 转换为DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = a2p(trainpath)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "b'1'    292\n",
       "b'2'    177\n",
       "b'4'     19\n",
       "b'3'     10\n",
       "b'5'      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
